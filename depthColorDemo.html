<html>
<head>
</head>

<style>
  body {
    display: flex;
    flex-direction: column;
    font-family: 'Roboto', 'Noto', sans-serif;
    line-height: 1.5;
    background-color: #fbfbfb;
    margin: 20px;
  }

  .select {
    margin: 16px 0px;
    display: flex;
    flex-direction: column;
    max-width: 400px;
  }

  select {
    background-color: transparent;
    width: 100%;
    padding: 4px 0;
    font-size: 16px;
    color: rgba(0,0,0, 0.26);
    border: none;
    border-bottom: 1px solid rgba(0,0,0, 0.12);
  }

  select:focus {
    outline: none;
  }

  .select > label {
    font-size: 10pt;
    color: gray;
  }

  #console {
    color: red;
    font-size: 150%;
  }

  canvas {
    border: 1px solid #cccccd;
    background-color: white;
  }

  #tabcontainer {
    margin: 16px 0px;
  }

  #tabcontainer input {
    height: 35px;
    visibility: hidden;
  }

  label[for=tab1], label[for=tab2] {
    color: gray;
    cursor: pointer;
    display: block;
    float: left;
    height, : 40px;
    line-height: 40px;
    margin-right: 5px;
    padding: 0 20px;
    text-align: center;
  }
  
  #tabcontainer input:hover + label {
    background: lightgray;
    color: gray;
  }

  #tabcontainer input:checked + label {
    background: #f0f0f0;
    color: dimgray;
    position: relative;
    z-index: 6;
  }

  #tabcontent1, #tabcontent2 {
    background: #f0f0f0;
    opacity: 0;
    position: absolute;
    z-index: -100;
  }

  #tabcontainer input#tab1:checked ~ #tabcontent #tabcontent1,
  #tabcontainer input#tab2:checked ~ #tabcontent #tabcontent2 {
      opacity: 1;
      z-index: 100;
  }

  input.visible {
    visibility: visible !important;
  }


  video-stream {
    color: dimgray;
  }

  #synctab {
    margin: 16px;
    padding:0px;
    color: dimgray;
  }

  label[for=synccanvas] {
    display:block;    
  }

  #show-background-video {
    position: absolute;
    bottom: 50px;
    right: 25px;
    color: gray;
    z-index: 5;
    height: 20px;
    text-align: right;
  }
  #show-background-color {
    position: absolute;
    bottom: 30px;
    right: 25px;
    color: gray;
    z-index: 5;
    height: 20px;
    text-align: right;
  }
  #show-video-toggle, #show-color-toggle {
    visibility: visible !important;
    height: 15px !important;
    vertical-align:middle;
  }
</style>

<template id="video-stream">
  <style>
    :host {
      display: flex;
      flex-flow: row wrap;
    }

    canvas {
      align-self: center;
    }

    div {
      margin: 16px;
    }

    label {
      display: block;
    }
  </style>
  <div>
    <label>WebGL2.0-Compute Powered ICP wglFusion:</label>
    <canvas id="canvasGL" width="1696" height="720"></canvas>
  </div>
</template>

<body onload="onLoad()">
  <h2>wglFusion Demo</h2>
  <div id="console">
    <!-- Print error messages here. -->
  </div>
  <div class="select">
    <label for="selectVideoDevice">Capture device with depth stream</label>
    <select id="selectVideoDevice"></select>
  </div>
  <div class="slidecontainer">
    <p>Lenght in m: <span id="volLength"></span></p>
    <input type="range" min="0.05" max="5" step="0.01" value="0.5" class="slider" id="volumeLength">
    <p>Resolution in voxels: <span id="numVox"></span></p>
    <input type="range" min="5" max="9" step="1" value="6" class="slider" id="numberVoxels">
  </div>
  <div id="buttoncontainer">
    <button onclick="resetVolume()">Reset Volume</button>
    <button onclick="integrateClick()">Integrate Volume</button>
    <input type="radio" id="integrateRadio" checked>
    <button onclick="clickPoseNet()">Load PoseNet</button>

  </div>
  <div>
    <button onclick="renderDepthClick()">Render Depth</button>
    <input type="radio" id="renderDepthRadio" checked>
    <button onclick="renderColorClick()">Render Color</button>
    <input type="radio" id="renderColorRadio">
    <button onclick="renderRefNormClick()">Render refNorm</button>
    <input type="radio" id="renderRefNormRadio">
    <button onclick="renderRefVertClick()">Render refVert</button>
    <input type="radio" id="renderRefVertRadio">
    <button onclick="renderNormClick()">Render Norm</button>
    <input type="radio" id="renderNormRadio">
    <button onclick="renderVertClick()">Render Vert</button>
    <input type="radio" id="renderVertRadio">
  </div>
  <div id="tabcontainer">
    <input id="tab1" type="radio" name="tabs" value="basic" checked="checked" data-ontaboff="stopBasicTab" data-ontabon="startBasicTab"/>
    <div id="tabcontent">
      <div id = tabcontent1>
        <video-stream></video-stream>
      </div>
  </div>
  <script src="node_modules/gl-matrix/gl-matrix-min.js"></script>
  <script src="node_modules/luqr/luqr.min.js"></script>
  <script src="node_modules/mathjs/dist/math.js"></script>
  <script src="node_modules/stats.js/build/stats.min.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>


  <script src="src/createAndCompileShader.js"></script>
  <script src="src/createComputeProgram.js"></script>
  <script src="src/createRenderProgram.js"></script>
  <script src="src/volume.js"></script>
  <script src="src/frame.js"></script>
  <script src="src/generateTexture.js"></script>
  <script src="src/reset.js"></script>
  <script src="depth-camera.js"></script>
  <script src="src/track.js"></script>
  <script src="src/render.js"></script>
  <script src="src/renderSkeleton.js"></script>


  <script src="shaders/depthToVert.js"></script>
  <script src="shaders/vertToNorm.js"></script>
  <script src="shaders/raycastVolume.js"></script>
  <script src="shaders/integrateVolume.js"></script>
  <script src="shaders/trackP2P.js"></script>
  <script src="shaders/reduceP2P.js"></script>
  <script src="shaders/trackP2V.js"></script>
  <script src="shaders/reduceP2V.js"></script>
  <script src="shaders/renderScreen.js"></script>
  <script src="shaders/getClickedPoint.js"></script>
  <script src="shaders/ploting.js"></script>
  <script src="shaders/skeleton.js"></script>

</body>









<script>
  let error = window.console.error;
  window.console.error = (message, ...rest) => {
    let target = document.querySelector('#console');
    error.call(window.console, message, ...rest);

    if (message instanceof Error) {
      message = `${message.name}: ${message.message}`;
    }

    target.innerHTML += `${message}<br>`;
  }

  function clickPoseNet() {
    loadPoseNet();
  }

  async function loadPoseNet() {
    net = await posenet.load({
  architecture: 'ResNet50',
  outputStride: 32,
  inputResolution: { width: 257, height: 200 },
  quantBytes: 2
});


    poseNetLoaded = 1;  

  }

  async function getBodyPose(image, net) {
    var bPWorking = 0;
    if (bodyPoseFound == 0 && bPWorking == 0)
    {
      bPWorking = 1;
      bodyPoseFound = 0;
      const bP = await net.estimateSinglePose(image, {flipHorizontal: false});
      bodyPose = JSON.parse(JSON.stringify(bP));
      bodyPoseFound = 1;
      bpWorking = 0;
    }
    

  }


  function resetVolume() {

    integrateFlag = 0;
    resetFlag = 1;
    pose = [...initPose];

    volSize = [Math.pow(2,sliderNumberVoxels.value), Math.pow(2,sliderNumberVoxels.value), Math.pow(2,sliderNumberVoxels.value)]
  

  
  }

  function integrateClick() {
    integrateFlag = 1 - integrateFlag;
    var intFlag = document.getElementById("integrateRadio");

    if (integrateFlag == 1) {
      intFlag.checked = true;
    }
    else {
      intFlag.checked = false;
    }
  }

  function renderDepthClick() {
    renderDepthFlag = 1 - renderDepthFlag;
    let flag = document.getElementById("renderDepthRadio");
    flag.checked = renderDepthFlag == 1 ? true : false;
  }
  function renderColorClick() {
    renderColorFlag = 1 - renderColorFlag;
    let flag = document.getElementById("renderColorRadio");
    flag.checked = renderColorFlag == 1 ? true : false;
  }
  function renderRefNormClick() {
    renderRefNormFlag = 1 - renderRefNormFlag;
    let flag = document.getElementById("renderRefNormRadio");
    flag.checked = renderRefNormFlag == 1 ? true : false;
  }
  function renderRefVertClick() {
    renderRefVertFlag = 1 - renderRefVertFlag;
    let flag = document.getElementById("renderRefVertRadio");
    flag.checked = renderRefVertFlag == 1 ? true : false;
  }
  function renderVertClick() {
    renderVertFlag = 1 - renderVertFlag;
    let flag = document.getElementById("renderVertRadio");
    flag.checked = renderVertFlag == 1 ? true : false;
  }
  function renderNormClick() {
    renderNormFlag = 1 - renderNormFlag;
    let flag = document.getElementById("renderNormRadio");
    flag.checked = renderNormFlag == 1 ? true : false;
  }

  let tabs = document.getElementsByName("tabs");
  let videos = {depth: null, color: null};

  let selectedtab = tabs[0];
  for(let i = 0; i < tabs.length; i++) {
    tabs[i].onclick = function() {
      if(this !== selectedtab) {
        window[selectedtab.dataset.ontaboff](); 
        selectedtab = this;
        window[selectedtab.dataset.ontabon](); 
      }
    };
  }
  
  function stopVideo(video) {
    if (video && video.srcObject) {
      const cs = video.srcObject;
      for (let track of cs.getTracks()) {
        track.stop();
      }
      video.srcObject = null;
    }
  }



  const videoToggle = document.getElementById("show-video-toggle");
  
  function getCursorPosition(canvas, event) {
    const rect = canvas.getBoundingClientRect();
    const x = event.clientX - rect.left;
    const y = event.clientY - rect.top;
    //console.log("x: " + x + " y: " + y);
    mouseClickPos[0] = x;
    mouseClickPos[1] = y;

  }





  // UI stuff
  var sliderVolumeLength = document.getElementById("volumeLength");
  var sliderNumberVoxels = document.getElementById("numberVoxels");

  var textVolumeLength = document.getElementById("volLength");
  var textNumberVoxels = document.getElementById("numVox");

  textVolumeLength.innerHTML = sliderVolumeLength.value;
  textNumberVoxels.innerHTML = Math.pow(2,sliderNumberVoxels.value);

  sliderVolumeLength.oninput = function() {
    textVolumeLength.innerHTML = this.value;
  }

  sliderNumberVoxels.oninput = function() {
    textNumberVoxels.innerHTML = Math.pow(2, this.value);
  }

  var stats = new Stats();
  stats.showPanel(0);
  stats.domElement.style.cssText = 'position:absolute;top:0px;right:0px;';
  document.body.appendChild(stats.dom);

  // vao
  var vaoPlotting;
  var vaoRender;
  var vaoSkeleton;

  // programs
  var depthToVertProg;
  var vertToNormProg;
  var integrateProg;
  var raycastProg;
  var p2pTrackProg;
  var p2pReduceProg;
  var p2vTrackProg;
  var p2vReduceProg;

  var plottingBufferProg;
  var clickedPointProg;
  var renderProgram;

  var plottingRenderProgram;
  var renderSkeletonProgram;

  var resetFlag = 0;
  var integrateFlag = 1;

  var renderDepthFlag = 1;
  var renderColorFlag = 0;
  var renderRefNormFlag = 0;
  var renderRefVertFlag = 0;
  var renderNormFlag = 0;
  var renderVertFlag = 0;

  var net;
  var poseNetLoaded = 0;
  var bodyPoseFound = 0;
  var bodyPose;



  var camPam = [420, 240, 420, 420]; // cx cy fx fy

  var K = glMatrix.mat4.create();
      K[0] = camPam[2];
      K[5] = camPam[3];
      K[8] = camPam[0];
      K[9] = camPam[1];

  var invK = glMatrix.mat4.create();
  glMatrix.mat4.invert(invK, K);
  //  	invK[0] = 1.0 / camPam[2];
  //    invK[5] = 1.0 / camPam[3];
  //    invK[8] = -camPam[0] / camPam[2];
  //    invK[9] = -camPam[1] / camPam[3];

  var volSize = [Math.pow(2,sliderNumberVoxels.value), Math.pow(2,sliderNumberVoxels.value), Math.pow(2,sliderNumberVoxels.value)];

  var imageSize = [848, 480];

  var pose = glMatrix.mat4.create();
  var initPose = glMatrix.mat4.create();
  var invIP = glMatrix.mat4.create();

  var graphXPoints = [];
  var graphYPoints = [];
  var graphZPoints = [];
  var graphTPoints = [];

  var frameCounter = 1;

  glMatrix.mat4.translate(pose, pose, [sliderVolumeLength.value / 2.0, sliderVolumeLength.value / 2.0, 0.0]);
  initPose = [...pose];
  glMatrix.mat4.invert(invIP, initPose);

  var mouseClickPos = [imageSize[0] / 2, imageSize[1] / 2];
  

  function normalize(val, max, min) { return (val - min) / (max - min); }


  customElements.define('video-stream', class extends HTMLElement {
    constructor() {
      super();
      const template = document.querySelector('#video-stream');
      const clone = document.importNode(template.content, true);
      const shadowRoot = this.attachShadow({ mode: 'open' });
      this.shadowRoot.appendChild(clone);

      this._frameLoop = this._frameLoop.bind(this);

      this.readBuffer = null;
      this.readFormat = null;
    }


    connectedCallback() {
      this.gl = this._configureGLContext();

      this.frameAvailable = false;
      this.frameAvailableColor = false;

      this.videoDepth = this._createOffscreenVideo();
      this.videoDepth.oncanplay = _ => { this.frameAvailable = true; }
      this.videoDepth.addEventListener("play", this._frameLoop);

      let hasTouchListeners = false;
      const onVideoTouchStart = _ => {
        hasTouchListeners = false;
        window.removeEventListener("touchstart", onVideoTouchStart, true);
        this.videoDepth.play();
      }

      if (this.videoDepth && this.videoDepth.paused && !hasTouchListeners) {
        hasTouchListeners = true;
        window.addEventListener("touchstart", onVideoTouchStart, true);
      }

      this.videoColor = this._createOffscreenVideo();
      this.videoColor.oncanplay = _ => { this.frameAvailableColor = true; }
      this.videoColor.addEventListener("play", this._frameLoopColor);

      let hasTouchListenersColor = false;
      const onVideoTouchStartColor = _ => {
        hasTouchListenersColor = false;
        window.removeEventListener("touchstart", onVideoTouchStartColor, true);
        this.videoColor.playColor();
      }

      if (this.videoColor && this.videoColor.paused && !hasTouchListenersColor) {
        hasTouchListenersColor = true;
        window.addEventListener("touchstart", onVideoTouchStartColor, true);
      }
    }

    _createOffscreenVideo() {
      return Object.assign(document.createElement("video"), {
        autoplay: true,
        loop: true,
        crossOrigin: "anonymous",
        width: imageSize[0],
        height: imageSize[1]
      });
    }
    
    _frameLoopColor() {

    }

    _frameLoop() {
      const gl = this.gl;
      stats.begin();

      let c = this.shadowRoot.getElementById("canvasGL");




      if (this.frameAvailable) {
        // Upload the video frame to texture.
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, gl.depth_texture);
		    gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, imageSize[0], imageSize[1], gl.RED, gl.FLOAT, this.videoDepth);
      }

      if (this.frameAvailableColor) {
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, gl.color_texture);
		    gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, imageSize[0], imageSize[1], gl.RGBA, gl.UNSIGNED_BYTE, this.videoColor);
      }

      if (poseNetLoaded == 1) {
        getBodyPose(this.videoColor, net);
        //console.log(bodyPose)


        


      }

 
      

      calcPoseP2P(gl, imageSize[0], imageSize[1]);
      //this._calcPoseP2V();

      uploadGraphPoints(gl, pose[12], pose[13], pose[14]);

      render(gl, c.width, c.height);

      if (bodyPoseFound == 1)
      {
        let skelePoints = [];

        const adjacentKeyPoints =
        posenet.getAdjacentKeyPoints(bodyPose.keypoints, 0.001);
        // // adjacentKeyPoints.forEach((keypoints) => {
        // //   skelePoints.push(keypoints[0].position.x);
        // //   skelePoints.push(keypoints[0].position.y);
        // //   //skelePoints.push(keypoints[1].position[0]);
        // //   //skelePoints.push(keypoints[1].position[1]);
        // // });
        //console.log(bodyPose);

        for (let iter = 0; iter < bodyPose.keypoints.length; iter++)
        {
          skelePoints.push(bodyPose.keypoints[iter].position.x);
          skelePoints.push(bodyPose.keypoints[iter].position.y);
        }
 
        bodyPoseFound = 0;

        gl.useProgram(renderSkeletonProgram);
        gl.bindVertexArray(gl.vaoSkeleton);
        gl.uniform2fv(gl.getUniformLocation(renderSkeletonProgram, "imageSize"), imageSize);
        gl.viewport(0, 240, c.width / 2.0, c.height - 240);

        gl.bindBuffer(gl.ARRAY_BUFFER, gl.skeleton_buffer);

        let sp = Float32Array.from(skelePoints);

        gl.bufferSubData(gl.ARRAY_BUFFER, 0, sp, 0, skelePoints.length);

        gl.drawArrays(gl.POINTS, 0, skelePoints.length);     

        gl.bindVertexArray(null);

      }

      frameCounter++;
      stats.end();
      if (!this.paused)
        window.requestAnimationFrame(this._frameLoop);
    }






    // Creates WebGL/WebGL2 context used to upload depth video to texture,
    // read the pixels to Float buffer and optionElally render the texture.
    _configureGLContext() {
      const canvas = this.shadowRoot.getElementById("canvasGL");
      const gl = canvas.getContext('webgl2-compute', {antialias: false});
      if (gl) {
        // The extension tells us if we can use single component R32F texture format.
        gl.color_buffer_float_ext = gl.getExtension('EXT_color_buffer_float');
      } else {
        gl = canvas.getContext("webgl");
        gl.getExtension("OES_texture_float");
      }
      // from https://stackoverflow.com/questions/55677/how-do-i-get-the-coordinates-of-a-mouse-click-on-a-canvas-element/18053642#18053642
      canvas.addEventListener('mousedown', function(e) {
        getCursorPosition(canvas, e)
      })


      // COMPUTE SHADERS
      depthToVertProg = createComputeProgram(gl, depthToVertSource);  
      vertToNormProg = createComputeProgram(gl, vertToNormSource);  
      integrateProg = createComputeProgram(gl, integrateSource);  
      raycastProg = createComputeProgram(gl, raycastSource);  
      p2pTrackProg = createComputeProgram(gl, p2pTrackSource);  
      p2pReduceProg = createComputeProgram(gl, p2pReduceSource);  
      p2vTrackProg = createComputeProgram(gl, p2vTrackSource);  
      p2vReduceProg = createComputeProgram(gl, p2vReduceSource);  
      clickedPointProg = createComputeProgram(gl, clickedPointSource);  
      plottingBufferProg = createComputeProgram(gl, plottingBufferSource);  
      // VERTEX FRAGMENT SHADERS
      plottingRenderProgram = createRenderProgram(gl, plottingVertexShaderSource, plottingFragmentShaderSource);
      renderProgram = createRenderProgram(gl, vertexShaderSource, fragmentShaderSource);
      renderSkeletonProgram = createRenderProgram(gl, skeletonVertexShaderSource, skeletonFragmentShaderSource);

            
      gl.enable(gl.BLEND);
      gl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA);

      // BINDING BUFFERS
      gl.useProgram(plottingRenderProgram);
      vaoPlotting = gl.createVertexArray();
      gl.bindVertexArray(vaoSkeleton);


      let emptyGraphPoints = new Float32Array(2*1024);
      var ssboGraphX = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboGraphX);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, emptyGraphPoints, gl.DYNAMIC_COPY);
      var ssboGraphY = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboGraphY);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, emptyGraphPoints, gl.DYNAMIC_COPY);
      var ssboGraphZ = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboGraphZ);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, emptyGraphPoints, gl.DYNAMIC_COPY);

      gl.bindBuffer(gl.ARRAY_BUFFER, ssboGraphX);
      gl.enableVertexAttribArray(1);
      gl.vertexAttribPointer(1, 2, gl.FLOAT, false, 0, 0);

      gl.bindBuffer(gl.ARRAY_BUFFER, ssboGraphY);
      gl.enableVertexAttribArray(2);
      gl.vertexAttribPointer(2, 2, gl.FLOAT, false, 0, 0);

      gl.bindBuffer(gl.ARRAY_BUFFER, ssboGraphZ);
      gl.enableVertexAttribArray(3);
      gl.vertexAttribPointer(3, 2, gl.FLOAT, false, 0, 0);
      gl.bindVertexArray(null);


      gl.useProgram(renderProgram);
      vaoRender = gl.createVertexArray();
      gl.bindVertexArray(vaoRender);

      var vertex_location = gl.getAttribLocation(renderProgram, "v");
      gl.enableVertexAttribArray(vertex_location);

      var vertex_buffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, vertex_buffer);
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([0,0,1,0,1,1,0,1]), gl.STATIC_DRAW);

      var index_buffer= gl.createBuffer();
      gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, index_buffer);
      gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, new Uint16Array([0,1,2,0,2,3]), gl.STATIC_DRAW);

      gl.bindBuffer(gl.ARRAY_BUFFER, gl.vertex_buffer);
      gl.enableVertexAttribArray(0);
      gl.vertexAttribPointer(0, 2, gl.FLOAT, false, 0, 0);

      gl.bindVertexArray(null);

      let arr = new Float32Array(imageSize[0] * imageSize[1] * 8);// width * height * sizeof reduType struct
      var ssboReduction = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboReduction);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, arr, gl.DYNAMIC_COPY);

      let arrOutput = new Float32Array(32 * 8);
      var ssboReductionOutput = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboReductionOutput);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, arrOutput, gl.DYNAMIC_COPY);

      let arrClicked = new Float32Array(4);
      var ssboClickedPoint = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboClickedPoint);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, arrClicked, gl.DYNAMIC_COPY);


      gl.useProgram(renderSkeletonProgram);
      vaoSkeleton = gl.createVertexArray();
      gl.bindVertexArray(vaoSkeleton);

      let arrSkele = new Float32Array(17 * 2);
      var skeleton_buffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, skeleton_buffer);
      gl.bufferData(gl.ARRAY_BUFFER, arrSkele, gl.DYNAMIC_COPY);

      gl.enableVertexAttribArray(0);
      gl.vertexAttribPointer(0, 2, gl.FLOAT, false, 0, 0);

      gl.bindVertexArray(null);

      var depth_texture = generateTexture(gl, gl.TEXTURE_2D, gl.R32F, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);
      var color_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA8, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);

      var volume_texture = generateTexture(gl, gl.TEXTURE_3D, gl.R32F, 1, volSize[0], volSize[1], volSize[2], gl.NEAREST, gl.NEAREST);
      var volumeWeight_texture = generateTexture(gl, gl.TEXTURE_3D, gl.R32F, 1, volSize[0], volSize[1], volSize[2], gl.NEAREST, gl.NEAREST);

      var render_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA8UI, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);
      var renderGraph_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA8UI, 1, 1024, 240, 1, gl.NEAREST, gl.NEAREST);

      var vertex_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);
      var normal_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);

      var refVertex_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);
      var refNormal_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);


      // Framebuffer for reading back the texture.
      var framebuffer = gl.createFramebuffer();
      gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);
      gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, render_texture, 0);
      gl.bindFramebuffer(gl.FRAMEBUFFER, null);

      // Framebuffer for reading back the texture.
      var framebufferGraph = gl.createFramebuffer();
      gl.bindFramebuffer(gl.FRAMEBUFFER, framebufferGraph);
      gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, renderGraph_texture, 0);
      gl.bindFramebuffer(gl.FRAMEBUFFER, null);


      gl.vertex_buffer = vertex_buffer;
      gl.vertex_location = vertex_location;
      gl.index_buffer = index_buffer;

      gl.skeleton_buffer = skeleton_buffer;

      gl.ssboReduction = ssboReduction;
      gl.ssboReductionOutput = ssboReductionOutput;
      gl.ssboClickedPoint = ssboClickedPoint;

      gl.ssboGraphX = ssboGraphX;
      gl.ssboGraphY = ssboGraphY;
      gl.ssboGraphZ = ssboGraphZ;

      gl.vaoPlotting = vaoPlotting;
      gl.vaoRender = vaoRender;
      gl.vaoSkeleton = vaoSkeleton;

      gl.depth_texture = depth_texture;
      gl.color_texture = color_texture;
      gl.vertex_texture = vertex_texture;
      gl.normal_texture = normal_texture;
      gl.volume_texture = volume_texture;      
      gl.volumeWeight_texture = volumeWeight_texture;
      gl.refVertex_texture = refVertex_texture;
      gl.refNormal_texture = refNormal_texture;
      gl.render_texture = render_texture;


      gl.framebuffer = framebuffer;
      gl.framebufferGraph = framebufferGraph;

      return gl;
    }

    async loadStream(deviceId) {
      stopVideo(videos.depth);
      stopVideo(videos.color);

      // If the item in drop-down list is selected, use it.
      const getUserMediaDepth = () => {
        // add ?allow=all to URL to allow listing all devices (incl. those not supporting depth).
        if (!deviceId && (new URL(window.location)).searchParams.get("allow") !== "all") {
          return DepthCamera.getDepthStream();
        }

        const constraints = {
          video: {
            deviceId: deviceId ? { exact: deviceId } : {}
          }
        }

        return navigator.mediaDevices.getUserMediaDepth(constraints);
      }

      const getUserMediaColor = () => {
        // add ?allow=all to URL to allow listing all devices (incl. those not supporting depth).
        if (!deviceId && (new URL(window.location)).searchParams.get("allow") !== "all") {
          return DepthCamera.getColorStream();
        }

        const constraints = {
          video: {
            deviceId: deviceId ? { exact: deviceId } : {}
          }
        }

        return navigator.mediaDevices.getUserMediaColor(constraints);
      }

      try {
        const streamDepth = await getUserMediaDepth();
        this.videoDepth.srcObject = streamDepth;
        videos.depth = this.videoDepth;

        const streamColor = await getUserMediaColor();
        this.videoColor.srcObject = streamColor;
        videos.color = this.videoColor;

        //videos.color = this.videoDepth;

        // Chrome, starting with version 59, implements getSettings() API.
        const tracksDepth = streamDepth.getVideoTracks()[0];
        if (tracksDepth.getSettings) {
          this.depthDeviceId = tracksDepth.getSettings().deviceId;
        }

        const tracksColor = streamColor.getVideoTracks()[0];
        if (tracksColor.getSettings) {
          this.colorDeviceId = tracksColor.getSettings().deviceId;
        }

      } catch (err) {
        console.error(err);
      }
    }
  });

  function populateSelectElement(devices) {
    const selectEl = document.querySelector('#selectVideoDevice');
    const videoStreamEl = document.querySelector('video-stream');

    let selected = selectEl.value;

    while (selectEl.firstChild) {
      selectEl.removeChild(selectEl.firstChild);
    }

    let selectedDeviceStillExists = false;
    for (let i = 0; i < devices.length; ++i) {
      const info = devices[i];
      if (info.kind !== 'videoinput') {
        continue;
      }

      const optionEl = document.createElement('option');
      optionEl.value = info.deviceId;
      optionEl.text = info.label || 'camera ' + (selectEl.length + 1);
      selectEl.appendChild(optionEl);

      if (optionEl.value === selected) {
        selectedDeviceStillExists = true;
      }
    }

    if (selectedDeviceStillExists) {
      selectEl.value = selected;
    } else if (!selected) {
      // If no other device is selected, set the initial selection to depth device.
      if (videoStreamEl.depthDeviceId) {
        selectEl.value = videoStreamEl.depthDeviceId;
      }
    }


  }

  function onLoad() {
    const videoStreamEl = document.querySelector('video-stream');
    const selectEl = document.querySelector('#selectVideoDevice');

    selectEl.onchange = async event => {
      selectEl.disabled = true;
      const deviceId = event.target.value;

      await videoStreamEl.loadStream(deviceId);

      const devices = await navigator.mediaDevices.enumerateDevices();
      populateSelectElement(devices);
      if (selectedtab.value != "basic") {
        // It is on by default; stop rendering it if not visible.
        stopBasicTab();
      }

      selectEl.disabled = false;
    };
    selectEl.dispatchEvent(new Event('change', { 'bubbles': true }))
  }
</script>
</html>
