<html>
<head>
</head>

<style>
  body {
    display: flex;
    flex-direction: column;
    font-family: 'Roboto', 'Noto', sans-serif;
    line-height: 1.5;
    background-color: #fbfbfb;
    margin: 20px;
  }

  .select {
    margin: 16px 0px;
    display: flex;
    flex-direction: column;
    max-width: 400px;
  }

  select:focus {
    outline: none;
  }

  .select > label {
    font-size: 10pt;
    color: gray;
  }

  #console {
    color: red;
    font-size: 150%;
  }

  canvas {
    border: 1px solid #cccccd;
    background-color: white;
  }

  #tabcontainer {
    margin: 16px 0px;
  }

  #tabcontainer input {
    height: 35px;
    visibility: hidden;
  }

  label[for=tab1], label[for=tab2] {
    color: gray;
    cursor: pointer;
    display: block;
    float: left;
    height, : 40px;
    line-height: 40px;
    margin-right: 5px;
    padding: 0 20px;
    text-align: center;
  }
  
  #tabcontainer input:hover + label {
    background: lightgray;
    color: gray;
  }

  #tabcontainer input:checked + label {
    background: #f0f0f0;
    color: dimgray;
    position: relative;
    z-index: 6;
  }

  #tabcontent1, #tabcontent2 {
    background: #f0f0f0;
    opacity: 0;
    position: absolute;
    z-index: -100;
  }

  #tabcontainer input#tab1:checked ~ #tabcontent #tabcontent1,
  #tabcontainer input#tab2:checked ~ #tabcontent #tabcontent2 {
      opacity: 1;
      z-index: 100;
  }

  input.visible {
    visibility: visible !important;
  }


  video-stream {
    color: dimgray;
  }

  #synctab {
    margin: 16px;
    padding:0px;
    color: dimgray;
  }

  label[for=synccanvas] {
    display:block;    
  }

  #show-background-video {
    position: absolute;
    bottom: 50px;
    right: 25px;
    color: gray;
    z-index: 5;
    height: 20px;
    text-align: right;
  }
  #show-background-color {
    position: absolute;
    bottom: 30px;
    right: 25px;
    color: gray;
    z-index: 5;
    height: 20px;
    text-align: right;
  }
  #show-video-toggle, #show-color-toggle {
    visibility: visible !important;
    height: 15px !important;
    vertical-align:middle;
  }
</style>

<template id="video-stream">
  <style>
    :host {
      display: flex;
      flex-flow: row wrap;
    }

    canvas {
      align-self: center;
    }

    div {
      margin: 16px;
    }

    label {
      display: block;
    }
  </style>

</template>

<body onload="onLoad()">
  <h2>wglFusion Demo</h2>
  <div id="no-support" style="display: none">
    <p><mark class="secondary" style="margin-right: 0.5em"></mark> It seems like WebGL 2.0 Compute is not available on your browser. Make sure you are on a system with WebGL 2.0 Compute enabled.</p>
    <p>Have you tried to open your browser using these arguments ?</p>
    <p>Windows: </p>
    <pre>chrome.exe --use-cmd-decoder=passthrough --use-angle=gl --enable-webgl2-compute-context</pre>
    <p>Linux - USE CHROME DEV: </p>
    <pre>google-chrome-unstable --use-gl=angle --use-angle=gl --use-cmd-decoder=passthrough --enable-webgl2-compute-context</pre>
  </div>
  <div id="console">
    <!-- Print error messages here. -->
  </div>
  <div>
    <label>WebGL2.0-Compute Powered ICP wglFusion:</label>
    <canvas id="canvasGL" width="1696" height="720"></canvas>
  </div>
 
  <script src="node_modules/gl-matrix/gl-matrix-min.js"></script>
  <script src="node_modules/luqr/luqr.min.js"></script>
  <script src="node_modules/mathjs/dist/math.js"></script>
  <script src="node_modules/stats.js/build/stats.min.js"></script>
  <script src="node_modules/dat.gui/build/dat.gui.min.js"></script>


  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>


  <script src="src/createAndCompileShader.js"></script>
  <script src="src/createComputeProgram.js"></script>
  <script src="src/createRenderProgram.js"></script>
  <script src="src/volume.js"></script>
  <script src="src/frame.js"></script>
  <script src="src/generateTexture.js"></script>
  <script src="src/reset.js"></script>
  <script src="depth-camera.js"></script>
  <script src="src/track.js"></script>
  <script src="src/render.js"></script>
  <script src="src/renderSkeleton.js"></script>


  <script src="shaders/depthToVert.js"></script>
  <script src="shaders/vertToNorm.js"></script>
  <script src="shaders/raycastVolume.js"></script>
  <script src="shaders/integrateVolume.js"></script>
  <script src="shaders/trackP2P.js"></script>
  <script src="shaders/reduceP2P.js"></script>
  <script src="shaders/trackP2V.js"></script>
  <script src="shaders/reduceP2V.js"></script>
  <script src="shaders/renderScreen.js"></script>
  <script src="shaders/getClickedPoint.js"></script>
  <script src="shaders/ploting.js"></script>
  <script src="shaders/skeleton.js"></script>

</body>









<script>
  let error = window.console.error;
  window.console.error = (message, ...rest) => {
    let target = document.querySelector('#console');
    error.call(window.console, message, ...rest);

    if (message instanceof Error) {
      message = `${message.name}: ${message.message}`;
    }

    target.innerHTML += `${message}<br>`;
  }












  function clickPoseNet() {
    loadPoseNet();
  }

  async function loadPoseNet() {
    net = await posenet.load({
  architecture: 'ResNet50',
  outputStride: 32,
  inputResolution: { width: 257, height: 200 },
  quantBytes: 2
});


    poseNetLoaded = 1;  

  }

  async function getBodyPose(image, net) {
    var bPWorking = 0;
    if (bodyPoseFound == 0 && bPWorking == 0)
    {
      bPWorking = 1;
      bodyPoseFound = 0;
      const bP = await net.estimateSinglePose(image, {flipHorizontal: false});
      bodyPose = JSON.parse(JSON.stringify(bP));
      bodyPoseFound = 1;
      bpWorking = 0;
    }
    

  }


  function resetVolume() {

    integrateFlag = 0;
    resetFlag = 1;
    pose = [...initPose];

    //volSize = [volResolution, volResolution, volResolution]
  

  
  }



  let tabs = document.getElementsByName("tabs");
  let videos = {depth: null, color: null};

  let selectedtab = tabs[0];
  for(let i = 0; i < tabs.length; i++) {
    tabs[i].onclick = function() {
      if(this !== selectedtab) {
        window[selectedtab.dataset.ontaboff](); 
        selectedtab = this;
        window[selectedtab.dataset.ontabon](); 
      }
    };
  }
  
  function stopVideo(video) {
    if (video && video.srcObject) {
      const cs = video.srcObject;
      for (let track of cs.getTracks()) {
        track.stop();
      }
      video.srcObject = null;
    }
  }



  const videoToggle = document.getElementById("show-video-toggle");
  
  function getCursorPosition(canvas, event) {
    const rect = canvas.getBoundingClientRect();
    const x = event.clientX - rect.left;
    const y = event.clientY - rect.top;
    //console.log("x: " + x + " y: " + y);
    mouseClickPos[0] = x;
    mouseClickPos[1] = y;

  }


  var gl;


  // UI stuff

  var volLength = 0.5;

  var paramGUI = function () {
    this.loadCamera = function() {
      connectedCallback();
      loadRealsense();
    }
    this.resetVol = function() {
      resetVolume();
    }
    this.integrateVol = true;
    this.length = 0.5;
    this.resolution = 128;
    this.renderDepth = true;
    this.renderColor = false;
    this.renderNormal = true;
  }

  var gui = new dat.GUI();
  var param = new paramGUI();

  gui.add(param, 'loadCamera').name('Load Realsense');
  var resetClick = gui.add(param, 'resetVol').name('Reset Volume');
  var integrateClick = gui.add(param, 'integrateVol').name('Integrate');
  var lengthSlider = gui.add(param, 'length', 0.05, 2.0);
  var resolutionSlider = gui.add(param, 'resolution', [64, 128, 256, 512]);
  var renderDepthClick = gui.add(param, 'renderDepth').name('Depth')
  var renderNormalClick = gui.add(param, 'renderNormal').name('Normals')

  integrateClick.onChange(function(value) {
    integrateFlag = value;
  });

  lengthSlider.onChange(function(value) {
    volLength = value;
  });

  resolutionSlider.onChange(function(value) {
    volSize = [value, value, value];
  });

  renderDepthClick.onChange(function(value) {
    renderDepthFlag = value;
  });

  renderNormalClick.onChange(function(value) {
    renderRefNormFlag = value;
  });


  var stats = new Stats();
  stats.showPanel(0);
  stats.domElement.style.cssText = 'position:absolute;top:0px;right:0px;';
  document.body.appendChild(stats.dom);

  var videoDevices = [];


  // vao
  var vaoPlotting;
  var vaoRender;
  var vaoSkeleton;

  // programs
  var depthToVertProg;
  var vertToNormProg;
  var integrateProg;
  var raycastProg;
  var p2pTrackProg;
  var p2pReduceProg;
  var p2vTrackProg;
  var p2vReduceProg;

  var plottingBufferProg;
  var clickedPointProg;
  var renderProgram;

  var plottingRenderProgram;
  var renderSkeletonProgram;

  var resetFlag = 0;
  var integrateFlag = 1;

  var renderDepthFlag = 1;
  var renderColorFlag = 0;
  var renderRefNormFlag = 0;
  var renderRefVertFlag = 0;
  var renderNormFlag = 0;
  var renderVertFlag = 0;

  var net;
  var poseNetLoaded = 0;
  var bodyPoseFound = 0;
  var bodyPose;



  var camPam = [420, 240, 420, 420]; // cx cy fx fy

  var K = glMatrix.mat4.create();
      K[0] = camPam[2];
      K[5] = camPam[3];
      K[8] = camPam[0];
      K[9] = camPam[1];

  var invK = glMatrix.mat4.create();
  glMatrix.mat4.invert(invK, K);
  //  	invK[0] = 1.0 / camPam[2];
  //    invK[5] = 1.0 / camPam[3];
  //    invK[8] = -camPam[0] / camPam[2];
  //    invK[9] = -camPam[1] / camPam[3];

  var newImage = 1;
  var frameAvailableColor = false;
  var frameAvailableDepth = false;

  var volSize = [128, 128, 128];

  var imageSize = [848, 480];

  var pose = glMatrix.mat4.create();
  var initPose = glMatrix.mat4.create();
  var invIP = glMatrix.mat4.create();

  var graphXPoints = [];
  var graphYPoints = [];
  var graphZPoints = [];
  var graphTPoints = [];

  var frameCounter = 1;

  glMatrix.mat4.translate(pose, pose, [volLength / 2.0, volLength / 2.0, 0.0]);
  initPose = [...pose];
  glMatrix.mat4.invert(invIP, initPose);

  var mouseClickPos = [imageSize[0] / 2, imageSize[1] / 2];
  

  function normalize(val, max, min) { return (val - min) / (max - min); }


  function connectedCallback() {

frameAvailableColor = false;

// this.videoColor = this._createOffscreenVideo();
// this.videoColor.oncanplay = _ => { frameAvailableColor = true; }
// this.videoColor.addEventListener("play", this._frameLoop);

// let hasTouchListeners = false;
// const onVideoTouchStart = _ => {
//   hasTouchListeners = false;
//   window.removeEventListener("touchstart", onVideoTouchStart, true);
//   this.videoColor.play();
// }

// if (this.videoColor && this.videoColor.paused && !hasTouchListeners) {
//   hasTouchListeners = true;
//   window.addEventListener("touchstart", onVideoTouchStart, true);
// }

videos.color = this._createOffscreenVideo();
videos.color.oncanplay = _ => { frameAvailableColor = true; }

videos.depth = this._createOffscreenVideo();
videos.depth.oncanplay = _ => { frameAvailableDepth = true; }

videos.color.addEventListener("play", this.frameLoop); // fires when the color feed becomes available

}

function _createOffscreenVideo() {
return Object.assign(document.createElement("video"), {
  autoplay: true,
  loop: true,
  crossOrigin: "anonymous",
  width: imageSize[0],
  height: imageSize[1]
});
}

  async function frameLoop() {
      stats.begin();

      let c = document.getElementById("canvasGL");




      if (frameAvailableDepth) {
        // Upload the video frame to texture.
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, gl.depth_texture);
		    gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, imageSize[0], imageSize[1], gl.RED, gl.FLOAT, videos.depth);
      }

      if (frameAvailableColor) {
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, gl.color_texture);
		    gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, imageSize[0], imageSize[1], gl.RGBA, gl.UNSIGNED_BYTE, videos.color);
      }

      if (poseNetLoaded == 1) {
        getBodyPose(videos.color, net);
        //console.log(bodyPose)


        


      }

 
      

      calcPoseP2P(gl, imageSize[0], imageSize[1]);
      //this._calcPoseP2V();

      uploadGraphPoints(gl, pose[12], pose[13], pose[14]);

      render(gl, c.width, c.height);

      if (bodyPoseFound == 1)
      {
        let skelePoints = [];

        const adjacentKeyPoints =
        posenet.getAdjacentKeyPoints(bodyPose.keypoints, 0.001);
        // // adjacentKeyPoints.forEach((keypoints) => {
        // //   skelePoints.push(keypoints[0].position.x);
        // //   skelePoints.push(keypoints[0].position.y);
        // //   //skelePoints.push(keypoints[1].position[0]);
        // //   //skelePoints.push(keypoints[1].position[1]);
        // // });
        //console.log(bodyPose);

        for (let iter = 0; iter < bodyPose.keypoints.length; iter++)
        {
          skelePoints.push(bodyPose.keypoints[iter].position.x);
          skelePoints.push(bodyPose.keypoints[iter].position.y);
        }
 
        bodyPoseFound = 0;

        gl.useProgram(renderSkeletonProgram);
        gl.bindVertexArray(gl.vaoSkeleton);
        gl.uniform2fv(gl.getUniformLocation(renderSkeletonProgram, "imageSize"), imageSize);
        gl.viewport(0, 240, c.width / 2.0, c.height - 240);

        gl.bindBuffer(gl.ARRAY_BUFFER, gl.skeleton_buffer);

        let sp = Float32Array.from(skelePoints);

        gl.bufferSubData(gl.ARRAY_BUFFER, 0, sp, 0, skelePoints.length);

        gl.drawArrays(gl.POINTS, 0, skelePoints.length);     

        gl.bindVertexArray(null);

      }

      frameCounter++;
      stats.end();
      if (!this.paused)
        window.requestAnimationFrame(frameLoop);
    }

  function populateSelectElement(devices) {
    const selectEl = document.querySelector('#selectVideoDevice');
    const videoStreamEl = document.querySelector('video-stream');

    let selected = selectEl.value;

    while (selectEl.firstChild) {
      selectEl.removeChild(selectEl.firstChild);
    }

    let selectedDeviceStillExists = false;
    for (let i = 0; i < devices.length; ++i) {
      const info = devices[i];
      if (info.kind !== 'videoinput') {
        continue;
      }

      const optionEl = document.createElement('option');
      optionEl.value = info.deviceId;
      optionEl.text = info.label || 'camera ' + (selectEl.length + 1);
      selectEl.appendChild(optionEl);

      if (optionEl.value === selected) {
        selectedDeviceStillExists = true;
      }
    }

    if (selectedDeviceStillExists) {
      selectEl.value = selected;
    } else if (!selected) {
      // If no other device is selected, set the initial selection to depth device.
      if (videoStreamEl.depthDeviceId) {
        selectEl.value = videoStreamEl.depthDeviceId;
      }
    }


  }


  function setTextures(gl) {

    var depth_texture = generateTexture(gl, gl.TEXTURE_2D, gl.R32F, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);
      var color_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA8, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);

      var volume_texture = generateTexture(gl, gl.TEXTURE_3D, gl.R32F, 1, volSize[0], volSize[1], volSize[2], gl.NEAREST, gl.NEAREST);
      var volumeWeight_texture = generateTexture(gl, gl.TEXTURE_3D, gl.R32F, 1, volSize[0], volSize[1], volSize[2], gl.NEAREST, gl.NEAREST);

      var render_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA8UI, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);
      var renderGraph_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA8UI, 1, 1024, 240, 1, gl.NEAREST, gl.NEAREST);

      var vertex_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);
      var normal_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);

      var refVertex_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);
      var refNormal_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);


      // Framebuffer for reading back the texture.
      var framebuffer = gl.createFramebuffer();
      gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);
      gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, render_texture, 0);
      gl.bindFramebuffer(gl.FRAMEBUFFER, null);

      // Framebuffer for reading back the texture.
      var framebufferGraph = gl.createFramebuffer();
      gl.bindFramebuffer(gl.FRAMEBUFFER, framebufferGraph);
      gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, renderGraph_texture, 0);
      gl.bindFramebuffer(gl.FRAMEBUFFER, null);


     

      gl.depth_texture = depth_texture;
      gl.color_texture = color_texture;
      gl.vertex_texture = vertex_texture;
      gl.normal_texture = normal_texture;
      gl.volume_texture = volume_texture;      
      gl.volumeWeight_texture = volumeWeight_texture;
      gl.refVertex_texture = refVertex_texture;
      gl.refNormal_texture = refNormal_texture;
      gl.render_texture = render_texture;


      gl.framebuffer = framebuffer;
      gl.framebufferGraph = framebufferGraph;
  }

  function setBuffers(gl) {
    gl.enable(gl.BLEND);
      gl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA);

      // BINDING BUFFERS
      gl.useProgram(plottingRenderProgram);
      vaoPlotting = gl.createVertexArray();
      gl.bindVertexArray(vaoPlotting);


      let emptyGraphPoints = new Float32Array(2*1024);
      var ssboGraphX = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboGraphX);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, emptyGraphPoints, gl.DYNAMIC_COPY);
      var ssboGraphY = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboGraphY);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, emptyGraphPoints, gl.DYNAMIC_COPY);
      var ssboGraphZ = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboGraphZ);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, emptyGraphPoints, gl.DYNAMIC_COPY);

      gl.bindBuffer(gl.ARRAY_BUFFER, ssboGraphX);
      gl.enableVertexAttribArray(1);
      gl.vertexAttribPointer(1, 2, gl.FLOAT, false, 0, 0);

      gl.bindBuffer(gl.ARRAY_BUFFER, ssboGraphY);
      gl.enableVertexAttribArray(2);
      gl.vertexAttribPointer(2, 2, gl.FLOAT, false, 0, 0);

      gl.bindBuffer(gl.ARRAY_BUFFER, ssboGraphZ);
      gl.enableVertexAttribArray(3);
      gl.vertexAttribPointer(3, 2, gl.FLOAT, false, 0, 0);
      gl.bindVertexArray(null);


      gl.useProgram(renderProgram);
      vaoRender = gl.createVertexArray();
      gl.bindVertexArray(vaoRender);

      var vertex_location = gl.getAttribLocation(renderProgram, "v");
      gl.enableVertexAttribArray(vertex_location);

      var vertex_buffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, vertex_buffer);
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([0,0,1,0,1,1,0,1]), gl.STATIC_DRAW);

      var index_buffer= gl.createBuffer();
      gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, index_buffer);
      gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, new Uint16Array([0,1,2,0,2,3]), gl.STATIC_DRAW);

      gl.bindBuffer(gl.ARRAY_BUFFER, gl.vertex_buffer);
      gl.enableVertexAttribArray(0);
      gl.vertexAttribPointer(0, 2, gl.FLOAT, false, 0, 0);

      gl.bindVertexArray(null);

      let arr = new Float32Array(imageSize[0] * imageSize[1] * 8);// width * height * sizeof reduType struct
      var ssboReduction = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboReduction);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, arr, gl.DYNAMIC_COPY);

      let arrOutput = new Float32Array(32 * 8);
      var ssboReductionOutput = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboReductionOutput);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, arrOutput, gl.DYNAMIC_COPY);

      let arrClicked = new Float32Array(4);
      var ssboClickedPoint = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboClickedPoint);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, arrClicked, gl.DYNAMIC_COPY);


      gl.useProgram(renderSkeletonProgram);
      vaoSkeleton = gl.createVertexArray();
      gl.bindVertexArray(vaoSkeleton);

      let arrSkele = new Float32Array(17 * 2);
      var skeleton_buffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, skeleton_buffer);
      gl.bufferData(gl.ARRAY_BUFFER, arrSkele, gl.DYNAMIC_COPY);

      gl.enableVertexAttribArray(0);
      gl.vertexAttribPointer(0, 2, gl.FLOAT, false, 0, 0);

      gl.bindVertexArray(null);

      gl.vertex_buffer = vertex_buffer;
      gl.vertex_location = vertex_location;
      gl.index_buffer = index_buffer;

      gl.skeleton_buffer = skeleton_buffer;

      gl.ssboReduction = ssboReduction;
      gl.ssboReductionOutput = ssboReductionOutput;
      gl.ssboClickedPoint = ssboClickedPoint;

      gl.ssboGraphX = ssboGraphX;
      gl.ssboGraphY = ssboGraphY;
      gl.ssboGraphZ = ssboGraphZ;

      gl.vaoPlotting = vaoPlotting;
      gl.vaoRender = vaoRender;
      gl.vaoSkeleton = vaoSkeleton;
  }

  function initGL(gl) {
      // COMPUTE SHADERS
      depthToVertProg = createComputeProgram(gl, depthToVertSource);  
      vertToNormProg = createComputeProgram(gl, vertToNormSource);  
      integrateProg = createComputeProgram(gl, integrateSource);  
      raycastProg = createComputeProgram(gl, raycastSource);  
      p2pTrackProg = createComputeProgram(gl, p2pTrackSource);  
      p2pReduceProg = createComputeProgram(gl, p2pReduceSource);  
      p2vTrackProg = createComputeProgram(gl, p2vTrackSource);  
      p2vReduceProg = createComputeProgram(gl, p2vReduceSource);  
      clickedPointProg = createComputeProgram(gl, clickedPointSource);  
      plottingBufferProg = createComputeProgram(gl, plottingBufferSource);  
      // VERTEX FRAGMENT SHADERS
      plottingRenderProgram = createRenderProgram(gl, plottingVertexShaderSource, plottingFragmentShaderSource);
      renderProgram = createRenderProgram(gl, vertexShaderSource, fragmentShaderSource);
      renderSkeletonProgram = createRenderProgram(gl, skeletonVertexShaderSource, skeletonFragmentShaderSource);
  }

  // Creates WebGL/WebGL2 context used to upload depth video to texture,
    // read the pixels to Float buffer and optionElally render the texture.
    function configureGLContext() {
      const canvas = document.getElementById("canvasGL");
      var ctx = canvas.getContext('webgl2-compute', {antialias: false});

      canvas.addEventListener('mousedown', function(e) {
        getCursorPosition(canvas, e)
      });

      if (ctx) {
        // The extension tells us if we can use single component R32F texture format.
        ctx.color_buffer_float_ext = ctx.getExtension('EXT_color_buffer_float');
        ctx.oes_texture_float_linear = ctx.getExtension('OES_texture_float_linear');

        if (!ctx.color_buffer_float_ext) {
          console.log("not supporting ext float");
        }
        if (!ctx.oes_texture_float_linear) {
          console.log("not supporting oes float");
        }
      } 
      else {
        document.getElementById("no-support").style.display = 'block';
        return;
        ctx = canvas.getContext("webgl");
        ctx.getExtension("OES_texture_float");
      }

      return ctx;
    }

  async function loadStream(deviceId) {
      stopVideo(videos.color);
  
      try {
        const streamColor = await getColorStream(imageSize[0], imageSize[1], deviceId);

        if (streamColor[1] == 'color') {
          videos.color.srcObject = streamColor[0];
          videos.color.width = imageSize[0];
          videos.color.height = imageSize[1];
          //videos.color = this.videoColor; 
        }
        else if (streamColor[1] == 'depth') {
          videos.depth.srcObject = streamColor[0];
          videos.depth.width = imageSize[0];
          videos.depth.height = imageSize[1];
          //videos.depth = this.videoDepth; 
        }
      } catch (err) {
        console.error(err);
      }
    }

  function loadRealsense() {
    for (let i = 0; i < videoDevices.length; i++) {
      loadStream(videoDevices[i])
    }
  }
  function onLoad() {

    navigator.mediaDevices.enumerateDevices()
      .then(function(devices) {
        devices.forEach(function(device) {
          //console.log(device.kind + ": " + device.label +
          //            " id = " + device.deviceId);
          if (device.kind == "videoinput") {
            videoDevices.push(device.deviceId);
            //loadStream(deviceId);
          }
        });
      })
      .catch(function(err) {
        console.log(err.name + ": " + err.message);
      });

    gl = this.configureGLContext();

    initGL(gl);
    setTextures(gl);
    setBuffers(gl);

    // const videoStreamEl = document.querySelector('video-stream');
    // const selectEl = document.querySelector('#selectVideoDevice');

    // selectEl.onchange = async event => {
    //   selectEl.disabled = true;
    //   const deviceId = event.target.value;

    //   await videoStreamEl.loadStream(deviceId);

    //   const devices = await navigator.mediaDevices.enumerateDevices();
    //   populateSelectElement(devices);
    //   if (selectedtab.value != "basic") {
    //     // It is on by default; stop rendering it if not visible.
    //     stopBasicTab();
    //   }

    //   selectEl.disabled = false;
    // };
    // selectEl.dispatchEvent(new Event('change', { 'bubbles': true }))
  }
</script>
</html>
